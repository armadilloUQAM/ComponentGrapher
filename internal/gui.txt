Bonjour Etienne,
Voilà nous avons eu 5 minutes de neige.

Nous avons aussi pris le temps de nous poser avec FJL pour réfléchir à quelques évolution côté fichiers de sortie et fichiers d’entrée de COMPOSITEGRAPHER. Notre pari c est que cela va prendre, que la communauté des scientifiques qui étudient les phénomènes historiques (mais pourlesquels il n y’ a pas forcément de modèles standard : la linguistique, l’évolution culturelle, la paléontologie, la microbiologie – souvenons nous des mitchondries) et la métagénomique) va potentiellement vouloir l’utiliser et donc on a besoin de fournir des sorties encore plus clef-en-main à des utilisateurs qui seront avant tout des biologistes lambda.

Je sais que tu es très occupé, et donc ce que je voudrais évaluer dans un premier temps c’est : accepterais tu d’upgrader COMPOSITEGRAPHER ? (avec l’objectif qu’il remplisse toutes les missions ci-dessous)
 
1)     La question de l’interface utilisateur.

En faut il une ou pas ? A mon avis, c’est facultatif.

 

2)     La question des fichiers d’entrée.

Il faudrait préciser ce que doit être un fichier d’entrée :
A mon avis, il y en a deux : une matrice rectanglulaire n*p  avec des données qualitatives (des variables catégoriques), sans données manquantes (pour le moment on ne sait pas les traiter). (qui est peut –être transformée en format nexus ?)
Mais il faudrait aussi ajouter un test de complétude de la matrice, et s’il y a des données manquantes, indiquer un warning aux utilisateurs: « attention votre matrice contient des données manquantes » et le programme s’arrête.
Et aussi, pour le moment, un fichier « dico », qui donne la correspondance entre ce qu’il y a dans la matrice et la nature de chaque état de caractère (composante).
La question ici est : que doit donner l’utilisateur ?
Le plus simple me parait une seule matrice avec des catégories, qu’il serait fabriqué sous excel et ensuite COMPISITEGRAPHER fait la cuisine interne qu’il faut pour que tourner. 
(la gestion des données quantitatives et manquantes, on réfléchira à ça plus à l’avenir, mais pas dès maintenant)
 
3)     Concernant les fichiers de sortie

Nous avons besoin de plus de sorties, exactement 6 sorties, plus simples.
Les voici :

3a) le nombre n de complexes (CC dans graphes avec arètes de type I only, n étant fixé par l’utilisateur, mais par défaut on donne tous les complexes).
Ces complexes devraient être présentés par taille décroissante (de celui qui a le plus de composantes, à celui qui a le moins de composantes), sous forme d’un tableau dans un fichier « complexes » :
complexe1 (liste composantes + nombre de samples contenant le complexe + liste détaillées des samples concernés)

 

typiquement :

complexe 1 \t bras rouge, œil bleu, nez rose \t 2 \t mickey, minnie

 

3b) le nombre n de composantes les PLUS stables, c’est-à-dire les composantes présentant le plus fort in-degree type 2 dans le graphe de type 2 (n fixé par l’utilisateur, par défaut on liste toutes les composantes). Ces composantes devraient être présentées par ordre décroissant (du plus stable au moins stable) dans un fichier « Most stable components », sous forme d’un tableau :
 
Component1 + valeur de in degree de type 2+ nombre de samples contenant le component 1 + liste détaillées des samples concernés)
Par exemple :
Bras rouge \t 147 \t 2\t mickey minnie
 
3c) le nombre n de composantes les MOINS stables, c’est-à-dire les composantes présentant le plus faible in-degree type 2 dans le graphe de type 2 (n fixé par l’utilisateur, par défaut on liste toutes les composantes). Ces composantes devraient être présentées par ordre croissant (du moins stable au plus stable) dans un fichier « Least stable components», sous forme d’un tableau :
 
Component1 + valeur de in degree de type 2+ nombre de samples contenant le component 1 + liste détaillées des samples concernés)
 
Par exemple :
Oeil violet \t 1 \t 3\t angelina tartanpion hulk
 
3d) Le nombre n des composantes qui sont des pivots (n fixé par l’utilisateur, par défaut on liste toutes les composantes pivots). Si les caractères ne sont pas pivots on ne les indique pas.
Ici il y a une astuce car il faut distinguer plusieurs types de pivots dans le fichier de sortie, donc faire plusieurs fichiers de sortie.

3d1)Dans un premier tableau « pivots-points d’articulation » :
Composante1 \t pivot global (articulation point dans graphe arète type 1,2,3) \t pivot global chevauchant (articulation point dans graphe arète type 3) \t pivot local chevauchant (articulation point qui deconnecte ces voisins directs dans graphe arète type 3 SI ON faisait déjà ca, sinon tant pis) \ t + nombre de samples contenant le component 1 + liste détaillées des samples concernés)
 
Par exemple :
Œil violet \t YES\t YES\t YES\t3\t angelina tartanpion hulk

3d2)Dans un second tableau « pivots-betweenness » : on présente un nombre n de composantes, classées par ordre décroissant des valeurs de betwenness. (n fixé par l’utilisateur, par défaut on liste toutes les composantes)

 
Composante1 \t valeur de betwenness (dans graphe arète type 1,2,3) \t valeur de betwenness (dans graphe arète type 3) \ t  nombre de samples contenant le component 1 \ t liste détaillées des samples concernés.
 
Par exemple :
Œil violet \t 187\t 150\t 3 \t angelina tartanpion hulk

3d3)Dans un troisieme tableau « pivots-triplets» : on présente un nombre n de composantes, classées par ordre décroissant des valeurs de %central in triplets. (n fixé par l’utilisateur, par défaut on liste toutes les composantes)

 
Composante1 \t valeur de %central in triplets (dans graphe arète type 3) \t  nombre de samples contenant le component 1 \ t liste détaillées des samples concernés.
 
Par exemple :
Œil violet \t 7% \t 3 \t angelina tartanpion hulk
 
Voila, dis nous si ca te parait jouable (mais en gros ce sont des sous-tableaux de tes gros tableaux).
Dis nous si tu préfères un coup de patte de Jananan.
Si tu pouvais l’implémenter, stp teste bien que ca trouve les mêmes résultats ; ) (qu’il n y a pas un petit bug caché)
Pour les tests statistiques, on verra ça par la suite.
 
Merci beaucoup d'avoir pris le temps de lire tout ca :)
Bonne journée,
Eric

Friday Linux.com published their list of "what might well be the best Linux distributions to be found from the ever-expanding crop of possibilities... according to task." Here's their winners (as chosen by Jack Wallen), along with a short excerpt of his analysis.
Best distro for sysadmins : Parrot Linux. "Based on Debian and offers nearly every penetration testing tool you could possibly want. You will also find tools for cryptography, cloud, anonymity, digital forensics, programming, and even productivity."
Best lightweight distribution: LXLE. "Manages to combine a perfect blend of small footprint with large productivity."
Best desktop distribution: Elementary OS "I'm certain Elementary OS Loki will do the impossible and usurp Linux Mint from the coveted 'best desktop distribution' for 2017."
Best Linux for IoT: Snappy Ubuntu Core "Can already be found in the likes of various hacker boards (such as the Raspberry Pi) as well as Erle-Copter drones, Dell Edge Gateways, Nextcloud Box, and LimeSDR."
Best non-enterprise server distribution: CentOS. "Since 2004, CentOS has enjoyed a massive community-driven support system."
Best enterprise server distribution: SUSE. "Don't be surprised if, by the end of 2017, SUSE further chips away at the current Red Hat market share."
Wallen also chose Gentoo for "Best distribution for those with something to prove," saying "This is for those who know Linux better than most and want a distribution built specifically to their needs... a source-based Linux distribution that starts out as a live instance and requires you to then build everything you need from source." And surprisingly, he didn't mention his own favorite Linux distro, Bodhi Linux, which he describes elsewhere as "a melding of Ubuntu and Enlightenment".

